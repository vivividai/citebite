# RAG API Trace Log

Generated: 2025-12-02T09:37:40.990Z

---

## 1. RAG Query Input

```json
{
  "collectionId": "5b186709-9f07-4e99-9917-3370018b0930",
  "query": "tell me about what does full self driving means, and how did it improved until now",
  "conversationHistoryLength": 0,
  "conversationHistory": [],
  "timestamp": "2025-12-02T09:37:40.992Z"
}
```

## 2. Hybrid Search Results

```json
{
  "totalChunks": 20,
  "chunks": [
    {
      "index": 0,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "chunkId": "81a35a82-a1d7-475c-80fa-f5ede688f37c",
      "chunkIndex": 3,
      "semanticScore": 0.69902215529328,
      "keywordScore": 0,
      "combinedScore": 0.0114754098360656,
      "contentPreview": "e autonomous driving of vehicles through technical\nmeans such as environment perception, planning decision-\nmaking, automatic control, etc., in order to improve driving\nsafety, efficiency and comfort. Autonomous driving\ntechnologies are usually categorized into different levels of\nautomation, rangin...",
      "contentLength": 954
    },
    {
      "index": 1,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "chunkId": "e80d16ab-d27a-4199-a870-1730256721db",
      "chunkIndex": 4,
      "semanticScore": 0.698008582848636,
      "keywordScore": 0,
      "combinedScore": 0.0112903225806452,
      "contentPreview": "automated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving. [2]\nAssisted driving systems: These mainly include blind spot\nmonitoring, lane keeping assist, adap...",
      "contentLength": 865
    },
    {
      "index": 2,
      "paperId": "818290bcede2ae9b1d29c9d126008b9e7cd4d353",
      "chunkId": "6801b2a8-d702-4649-b589-56e812fce983",
      "chunkIndex": 5,
      "semanticScore": 0.692699429878311,
      "keywordScore": 0,
      "combinedScore": 0.0111111111111111,
      "contentPreview": "l\ncannot avoid accidents. Such examples include the Tesla and Volvo XC90, where serious\ninjuries and even deaths have occurred. This is a consequence of rapid urbanization and\nthe demand for mobility. Nowadays, an autonomous vehicle is expected to have an impact\non increasing road safety and thus re...",
      "contentLength": 951
    },
    {
      "index": 3,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "chunkId": "0eaa50e8-4c03-4484-a976-3b4b1f49e08c",
      "chunkIndex": 7,
      "semanticScore": 0.691715650609838,
      "keywordScore": 0,
      "combinedScore": 0.0109375,
      "contentPreview": "driving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade [6,7].\nNotably, the complexity of ADSs operation in indeterminate environments raises\nthe challenge of div...",
      "contentLength": 999
    },
    {
      "index": 4,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "chunkId": "00d1773f-ebe8-4671-b5c4-2c1ffe53ab32",
      "chunkIndex": 6,
      "semanticScore": 0.690750660224062,
      "keywordScore": 0,
      "combinedScore": 0.0107692307692308,
      "contentPreview": "ring road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project [4].\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road. Further large scale automated driving studies were carried in Europe’s Eureka\nAppl. Sci.2022,12, 16...",
      "contentLength": 944
    },
    {
      "index": 5,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "chunkId": "dcbdcd70-fada-48ae-9e53-ae8d0098b19d",
      "chunkIndex": 6,
      "semanticScore": 0.690724379555894,
      "keywordScore": 0,
      "combinedScore": 0.0106060606060606,
      "contentPreview": "y. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information. Laws, regulations\nand standards for advanced driver assistance systems are\nbeginning to emerge, pro...",
      "contentLength": 766
    },
    {
      "index": 6,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "chunkId": "e3e24b73-4aff-4bad-88ee-d8b80d8ab951",
      "chunkIndex": 5,
      "semanticScore": 0.685972770121653,
      "keywordScore": 0,
      "combinedScore": 0.0104477611940298,
      "contentPreview": "er of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages.\nAdvanced Driver Assistance: Based on the Assisted\nDriving System, more automated functions are adde...",
      "contentLength": 932
    },
    {
      "index": 7,
      "paperId": "2a6459d12bc80b49bb1b802be38a29df0364b67a",
      "chunkId": "7eb01d93-00a0-4522-ad0d-54f84cc6bb9f",
      "chunkIndex": 7,
      "semanticScore": 0.68510074826865,
      "keywordScore": 0,
      "combinedScore": 0.0102941176470588,
      "contentPreview": ", we are witnessing the growing intelligence of\nvehicles, thanks to recent advancements in embedded systems,\nnavigation, sensors, data acquisition and dissemination, and\nbig data analytics [11], [12]. It started with assisted-driving\ntechnologies, namely, Advanced Driver-Assistance Systems\n(ADAS), i...",
      "contentLength": 953
    },
    {
      "index": 8,
      "paperId": "feb2333acd3123f1e77cbd32a284391a54585268",
      "chunkId": "f61eac8d-8b00-4896-b141-f690b29d4bd4",
      "chunkIndex": 45,
      "semanticScore": 0.684220941082312,
      "keywordScore": 0,
      "combinedScore": 0.0101449275362319,
      "contentPreview": "h and Reviews, 2024, 21(01), 2009–2020\n2015\ncruise control, lane-keeping assistance, and automatic emergency braking serve as building blocks for the gradual\nintegration of autonomous functionalities. These systems contribute to enhanced safety by assisting drivers and\nmitigating risks, paving the w...",
      "contentLength": 924
    },
    {
      "index": 9,
      "paperId": "a56a5a4affe2dd34904009027569eb5f6f142bd9",
      "chunkId": "5107b727-6e79-4183-94ea-f89868a9ca34",
      "chunkIndex": 4,
      "semanticScore": 0.683008347006574,
      "keywordScore": 0,
      "combinedScore": 0.01,
      "contentPreview": "mated, i.e., the vehicle can handle a few situations (such as lane\nchanging, autonomous emergency braking (AEB)), and the driver should be monitoring\nand ready to take over the vehicle at any instant. Level 4, which includes higher automation\nfeatures, has an automated driving system (ADS) that can ...",
      "contentLength": 953
    },
    {
      "index": 10,
      "paperId": "a1d024ad226b66302f6f1624ef411e023aed2289",
      "chunkId": "9ed0e3a4-22dc-4c6a-9fef-5de640c20c24",
      "chunkIndex": 27,
      "semanticScore": 0.681306177760951,
      "keywordScore": 0,
      "combinedScore": 0.00985915492957746,
      "contentPreview": "ving. After 2024, fully automatic driving will be realized with more advanced\nfunctions such as unmanned automatic driving and coordinated optimization control of vehicles and\nroads in the urban area....",
      "contentLength": 200
    },
    {
      "index": 11,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "chunkId": "becf6bcd-97ed-4c33-b5c1-679db500fe7a",
      "chunkIndex": 5,
      "semanticScore": 0.680288782790226,
      "keywordScore": 0,
      "combinedScore": 0.00972222222222222,
      "contentPreview": "tensive use of vehicle infrastructure, labour cost savings, congestion re-\nduction, environmental benefits and, above all, a reduced number of accidents, of which\n94%(±2.2%) are caused by drivers [1]. Furthermore, the annual consumer and societal\nbenefits of the AVs are estimated to reach $800 billi...",
      "contentLength": 1000
    },
    {
      "index": 12,
      "paperId": "a32f9566c196a9ecff40f89d79b5a124a3e06750",
      "chunkId": "604ff398-e2b4-4e30-8d65-db7faab88fae",
      "chunkIndex": 3,
      "semanticScore": 0.679458606345877,
      "keywordScore": 0,
      "combinedScore": 0.00958904109589041,
      "contentPreview": "ant cost\nfactor [2]. Moreover, the absolute majority of the innovation\nin modern cars is embodied by software [2]–[4].\nThis new paradigm is a great enabler for more automated\nand autonomous functions. The Society of Automotive En-\ngineers (SAE) classifies the levels of autonomy in 6 levels\n[5]: from...",
      "contentLength": 1000
    },
    {
      "index": 13,
      "paperId": "fdeba56b4ec840111c2aa5701359562ed49f541d",
      "chunkId": "16fbfedb-bfad-4cf3-97a8-124cd0051a0d",
      "chunkIndex": 26,
      "semanticScore": 0.678316649495882,
      "keywordScore": 0,
      "combinedScore": 0.00945945945945946,
      "contentPreview": "comfort, and efficiency. The analysis begins by\ntracking the historical progression of driver assistance systems, from primitive anti-lock braking systems\nto the advanced ADAS seen in modern vehicles. The focus is on comprehending the innovative\nbreakthroughs that have paved the path for the current...",
      "contentLength": 756
    },
    {
      "index": 14,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "chunkId": "0b46e7b3-744e-41b1-91b1-004cd0520e27",
      "chunkIndex": 7,
      "semanticScore": 0.677222145645811,
      "keywordScore": 0,
      "combinedScore": 0.00933333333333333,
      "contentPreview": "ving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process. Comprehensively adopting a\nvariety of sensors, including high-precision LIDAR,\nmillimetre-wave rada...",
      "contentLength": 997
    },
    {
      "index": 15,
      "paperId": "696771f18ad59f6932c3c8090b7bf7855ecb5518",
      "chunkId": "4ecb26a2-5287-418f-abe1-84b577f05e88",
      "chunkIndex": 6,
      "semanticScore": 0.676401889007082,
      "keywordScore": 0,
      "combinedScore": 0.00921052631578947,
      "contentPreview": "ased on information\nderived from sensors. The scientific approach to pro-\ngress in this area involves conducting comprehensive\ntests to assess the ability of vehicles to react to vari-\nous conditions. This contributes to improving their\nperformance and increasing reliability. In this con-\ntext, scie...",
      "contentLength": 908
    },
    {
      "index": 16,
      "paperId": "feb2333acd3123f1e77cbd32a284391a54585268",
      "chunkId": "d6c2f15f-e34c-4476-836f-3229a4c60cc0",
      "chunkIndex": 44,
      "semanticScore": 0.676265322796326,
      "keywordScore": 0,
      "combinedScore": 0.00909090909090909,
      "contentPreview": "autonomous vehicles\n(George, Baskar & Srikaanth, 2023, Krichen, 2023).\nTo address safety concerns in autonomous driving, there is a notable focus on enhancing sensor redundancy and fusion\ntechniques. By integrating diverse sensor technologies and ensuring multiple layers of sensing capabilities, veh...",
      "contentLength": 891
    },
    {
      "index": 17,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "chunkId": "1dce5fd2-3799-418a-8beb-c9af17c87c30",
      "chunkIndex": 9,
      "semanticScore": 0.674876646320068,
      "keywordScore": 0,
      "combinedScore": 0.00897435897435897,
      "contentPreview": "ng, etc., vehicle systems at L3 level are able to rely on their\nown sensors to sense the driving environment, but monitoring tasks still need to be led by the human driver, and human driver\nintervention is still required in emergency\nsituations.\nL4\nThe term \"high degree autonomous driving\" means tha...",
      "contentLength": 997
    },
    {
      "index": 18,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "chunkId": "fb58831b-46d5-4dbc-88ac-4acbf41cf03a",
      "chunkIndex": 91,
      "semanticScore": 0.674768103403111,
      "keywordScore": 0,
      "combinedScore": 0.00886075949367088,
      "contentPreview": "nd of the decade.\nNonetheless, a key to more sustainable progress towards the highest levels of autonomy is\na gradual adoption of the already available technologies, as already accomplished with\nADAS. The passenger vehicle demonstrator for low-speed autonomy addresses this chal-\nlenge and shows that...",
      "contentLength": 837
    },
    {
      "index": 19,
      "paperId": "fdeba56b4ec840111c2aa5701359562ed49f541d",
      "chunkId": "0f1dd7ff-8d83-4c2c-80c9-eec0c536469e",
      "chunkIndex": 8,
      "semanticScore": 0.674192283782585,
      "keywordScore": 0,
      "combinedScore": 0.00875,
      "contentPreview": "icles have ADAS built in from the start, which is improved when new vehicle models\nand features are introduced. The devices leverage a range of information sources to provide useful security\nfeatures. Automotive imagery is a combination of excellent imaging sensors that equal and outperform\nthe capa...",
      "contentLength": 818
    }
  ]
}
```

## 4. Built Context for LLM

```json
{
  "contextLength": 17669,
  "fullContext": "[1]\ne autonomous driving of vehicles through technical\nmeans such as environment perception, planning decision-\nmaking, automatic control, etc., in order to improve driving\nsafety, efficiency and comfort. Autonomous driving\ntechnologies are usually categorized into different levels of\nautomation, ranging from partially automated driving to fully\nautomated driving. Using the classification method of the\nSociety of Automotive Engineers (SAE), automated driving\ntechnologies are described by dividing them into 6 levels (L0-\nL5, shown in Table 1).\nDevelopment history: The development of automatic\ndriving technology can be traced back to decades ago, but in\nrecent years has experienced rapid development, from the\ninitial assisted driving system to fully automated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving.\n\n[2]\nautomated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving. \nAssisted driving systems: These mainly include blind spot\nmonitoring, lane keeping assist, adaptive cruise control,\nautomatic emergency braking and other functions. The driver\nremains the primary controller and needs to monitor and\noperate the vehicle at all times. Basic camera, radar and\nultrasonic sensors are used. The aim is to improve driving\nsafety and reduce some of the burden on the driver.\nCorresponds to SAE levels L1 and L2 above. reduces the\nnumber of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages.\n\n[3]\nl\ncannot avoid accidents. Such examples include the Tesla and Volvo XC90, where serious\ninjuries and even deaths have occurred. This is a consequence of rapid urbanization and\nthe demand for mobility. Nowadays, an autonomous vehicle is expected to have an impact\non increasing road safety and thus reduce accidents. All vehicle manufacturers strive to\nachieve the highest level of autonomy. To achieve this, it is necessary to ensure the accurate\ndetection of the environment and safe driving in different scenarios. The authors proposed\na new unified framework for fully autonomous vehicles that integrates multiple modules.\nClothoid was implemented on Hyundai I-30 vehicle with a customized sensory and control\nsystem. The modules used are described in detail in the system architecture. The proposed\nsolution includes modules that take into account safety, i.e., HD mapping, localization,\nenvironment perception, path planning, and control modules.\n\n[4]\ndriving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade .\nNotably, the complexity of ADSs operation in indeterminate environments raises\nthe challenge of diverse weather conditions and a need to account for agent behaviour,\nespecially in busy urban environments, where autonomous vehicles have advantages\nover human drivers . Furthermore, failure to correctly address these challenges has\nled to accidents that undermine public acceptance of ADSs . In the attempt to reflect\nlessons learned from various stakeholders, theSociety of Automotive Engineers(SAE) defined\nsix levels of driving autonomy where levelzerostands for no autonomy and levelsfour\nandfivestand for autonomy where no human interaction is required . Furthermore,\nthe autonomous systems and their design process must comply with functional safety\nrequirements, i.e., ISO26262 .\n\n[5]\nring road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project .\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road. Further large scale automated driving studies were carried in Europe’s Eureka\nAppl. Sci.2022,12, 168. https://doi.org/10.3390/app12010168https://www.mdpi.com/journal/applsci\n\nAppl. Sci.2022,12, 1682 of 24\nproject PROMETHEUS between 1987 and 1995. The project led to the development of\nVITA II by Daimler-Benz, which succeeded in automatically driving on highways .\nSince the first automated driving challenge organized by the US Department of Defense in\n2004—Defense Advanced Research Projects Agency’s(DARPA) Grand Challenge, autonomous\ndriving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade .\n\n[6]\ny. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information. Laws, regulations\nand standards for advanced driver assistance systems are\nbeginning to emerge, providing legal protection for the\npromotion and popularisation of the technology. Significantly\nimproving the user experience, more driving tasks can be\ncompleted by the system under specific conditions.\nFully Automatic Driving: The vehicle is able to complete\nthe driving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process.\n\n[7]\ner of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages.\nAdvanced Driver Assistance: Based on the Assisted\nDriving System, more automated functions are added, such as\nTraffic Jam Assist, Motorway Driving Assist and Automatic\nParking System. The driver still needs to be alert, but in some\ncases the vehicle is able to perform more driving tasks\nautonomously. The addition of laser radar (LiDAR), more\nadvanced camera and radar systems, as well as greater\ncomputing power and software algorithms, further reduces\nthe operational burden on the driver and increases driving\ncomfort and safety. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information.\n\n[8]\n, we are witnessing the growing intelligence of\nvehicles, thanks to recent advancements in embedded systems,\nnavigation, sensors, data acquisition and dissemination, and\nbig data analytics , . It started with assisted-driving\ntechnologies, namely, Advanced Driver-Assistance Systems\n(ADAS), including emergency braking, backup cameras, adap-\ntive cruise control, and self-parking systems . Around the\nworld, the number of ADAS systems rose from 90 million\nunits in 2014 to about 140 million in 2016, a 50% increase in\njust two years . According to the definitions of autonomous\nvehicles laid out by the Society of Automotive Engineers\n(SAE) International, the above systems mainly belong to Level\n1 and Level 2 of automation. Tesla’s Autopilot system also\nfalls in this category . Automotive manufacturers and\ntechnical companies, such as Google, Uber, Tesla, Mobileye,\nare investing heavily on higher levels of driving autonomation.\n\n[9]\nh and Reviews, 2024, 21(01), 2009–2020\n2015\ncruise control, lane-keeping assistance, and automatic emergency braking serve as building blocks for the gradual\nintegration of autonomous functionalities. These systems contribute to enhanced safety by assisting drivers and\nmitigating risks, paving the way for the broader acceptance of autonomous technologies.\nThe development and testing of autonomous systems involve extensive simulations and controlled environments.\nSimulated scenarios allow engineers to expose embedded systems to a wide range of situations, including rare and\ndangerous events, to validate their responses. This approach aids in refining algorithms, improving safety mechanisms,\nand ensuring the robustness of autonomous vehicles before real-world deployment. Enhancements in HMI design focus\non creating intuitive interfaces that facilitate effective communication between the vehicle and its occupants.\n\n[10]\nmated, i.e., the vehicle can handle a few situations (such as lane\nchanging, autonomous emergency braking (AEB)), and the driver should be monitoring\nand ready to take over the vehicle at any instant. Level 4, which includes higher automation\nfeatures, has an automated driving system (ADS) that can handle most dynamic driving\ntasks without human intervention . Ultimately, the vehicles are expected to handle\nall situations and become fully autonomous in SAE level 5. Today, level 2–4 vehicles are\nbeing tested and deployed in the market . For example, Tesla’s level 2 with autopilot\nsystem and level 3 with the fully self-driving mode  are commercially available .\nEven with remarkable advancements in CAV development, it would be unrealistic to\nanticipate zero system failures. It is widely acknowledged that CAVs may not handle all road\nincidents and will depend on human decisions , as the real world can be very uncertain.\n\n[11]\nving. After 2024, fully automatic driving will be realized with more advanced\nfunctions such as unmanned automatic driving and coordinated optimization control of vehicles and\nroads in the urban area.\n\n[12]\ntensive use of vehicle infrastructure, labour cost savings, congestion re-\nduction, environmental benefits and, above all, a reduced number of accidents, of which\n94%(±2.2%) are caused by drivers . Furthermore, the annual consumer and societal\nbenefits of the AVs are estimated to reach $800 billion by 2050 . Nevertheless, further\ndevelopment of automated driving systems relies on the advancements of scientific disci-\nplines and new technologies. While the combination of accumulated knowledge in vehicle\ndynamics, the emergence of deep learning and the availability of new sensor modalities\ncatalysed AVs research, the challenges of fail-operational architectural models and robust\nperception are yet to be solved .\nInitially, the public experienced autonomous driving through the pioneering road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project .\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road.\n\n[13]\nant cost\nfactor . Moreover, the absolute majority of the innovation\nin modern cars is embodied by software –.\nThis new paradigm is a great enabler for more automated\nand autonomous functions. The Society of Automotive En-\ngineers (SAE) classifies the levels of autonomy in 6 levels\n: from no automation (level 0) to full automation under\nall circumstances without any need for a handover of control\n(level 5). Advanced driver-assistance systems (ADAS), which\ntake over much of the driving tasks (under the assumption\nof the possibility of rapid handover to a human driver), are\nalready present in modern high-end cars. There are commercial\nThis work is supported by the Leicester AI Network, through a Research\nNetwork grant awarded by the Leicester Institute for Advanced Studies, the\nRoyal Society Summer Science Exhibition, and Zenzic\nlevel 2 and 3 autonomous vehicles, which take over all driving\nfunctions under predefined circumstances, yet these systems\nstill rely on the the possi\n\n[14]\ncomfort, and efficiency. The analysis begins by\ntracking the historical progression of driver assistance systems, from primitive anti-lock braking systems\nto the advanced ADAS seen in modern vehicles. The focus is on comprehending the innovative\nbreakthroughs that have paved the path for the current status of ADAS.\nThe poll looks into the essential elements and functionality of ADAS, covering everything from simple\nfeatures like adaptive cruise control and lane-keeping guidance to more sophisticated features like\nautomatic emergency braking and pedestrian detection. A thorough examination of the underlying\ntechnology, including as sensors, cameras, radar, and lidar systems, reveals insights into the problems and\nopportunities connected with each.\n\n[15]\nving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process. Comprehensively adopting a\nvariety of sensors, including high-precision LIDAR,\nmillimetre-wave radar, high-definition cameras and high-\nprecision maps, combined with powerful AI algorithms and\ncomputational capabilities, the vehicle can achieve true\ndriverlessness, improve traffic efficiency, reduce traffic\naccidents and provide a convenient way of travelling. L4 and\n\n\n67\nL5, which correspond to SAE levels, are the embodiment of\nmajor breakthroughs in algorithms and computing\ncapabilities, especially the maturity of AI and machine\nlearning technologies, and have far-reaching impacts on\ntraffic management, urban planning, and social and legal\nsystems, including employment, legal responsibilities, and\nethical issues.\nTable 1 Specific information\nHierarchy Specific information\nL0 L0, i.e.\n\n[16]\nased on information\nderived from sensors. The scientific approach to pro-\ngress in this area involves conducting comprehensive\ntests to assess the ability of vehicles to react to vari-\nous conditions. This contributes to improving their\nperformance and increasing reliability. In this con-\ntext, scientific research is emerging as a key driver for\nthe development and improvement of the autonomous\nvehicle industry and making it a necessary part of the\nfuture of transportation .\nThe technology enabling self-driving vehicles\noffers many advantages that will transform the way\nwe commute and transport goods. One of its key\ncomponents is path planning. Enhanced safety is one\nof the principal benefits. Self-driving vehicles elimi-\nnate the possibility of human error-related accidents\nby calculating and choosing the best route while con-\nsidering real-time data on traffic, weather, and road\nconditions.\n\n[17]\nautonomous vehicles\n(George, Baskar & Srikaanth, 2023, Krichen, 2023).\nTo address safety concerns in autonomous driving, there is a notable focus on enhancing sensor redundancy and fusion\ntechniques. By integrating diverse sensor technologies and ensuring multiple layers of sensing capabilities, vehicles can\nbuild a more comprehensive and accurate perception of their environment. This redundancy not only improves the\nreliability of embedded systems but also provides fail-safes in the event of sensor malfunctions. Innovations in ADAS\nplay a pivotal role in bridging the transition between conventional and autonomous driving. Features such as adaptive\n\nWorld Journal of Advanced Research and Reviews, 2024, 21(01), 2009–2020\n2015\ncruise control, lane-keeping assistance, and automatic emergency braking serve as building blocks for the gradual\nintegration of autonomous functionalities.\n\n[18]\nng, etc., vehicle systems at L3 level are able to rely on their\nown sensors to sense the driving environment, but monitoring tasks still need to be led by the human driver, and human driver\nintervention is still required in emergency\nsituations.\nL4\nThe term \"high degree autonomous driving\" means that in limited areas or limited\nenvironments (e.g. fixed parks, closed and semi-closed highways, etc.), the vehicle\ncan fully sense the environment and intervene autonomously in emergencies without the need for any intervention by the\nhuman driver. In Level L4, the vehicle can be free of steering wheel, accelerator and brake pedals, but its application can only\nbe limited to special scenarios and environments.\nL5\nThat is, fully automatic driving, L5 does not require a driver, nor does it require\nanyone to intervene with the steering wheel and throttle, braking, etc., and is not\nlimited to driving in specific scenarios, but can adapt to any scenario and environment of automatic driving.\n2.2.\n\n[19]\nnd of the decade.\nNonetheless, a key to more sustainable progress towards the highest levels of autonomy is\na gradual adoption of the already available technologies, as already accomplished with\nADAS. The passenger vehicle demonstrator for low-speed autonomy addresses this chal-\nlenge and shows that such applications as self-parking and autonomous delivery of goods\nare feasible with the current maturity of the sensors and computing paradigms.\nAnother encouraging research vector is ensuring the security and reliability of sen-\nsor data and SW/HW components. In this respect, we have devised a trust model for\nenhancing fusion that provides the operational status of the integrated components. Fur-\nthermore, the eventual acceptance of autonomous vehicles requires this information to be\nconveniently accessible in real-time via HMI.\n\n[20]\nicles have ADAS built in from the start, which is improved when new vehicle models\nand features are introduced. The devices leverage a range of information sources to provide useful security\nfeatures. Automotive imagery is a combination of excellent imaging sensors that equal and outperform\nthe capabilities of the human retina. This is in the form of 360-degree reach, 3D object quality, clarity in\ndifficult weather and lighting scenarios, and immediate information, that is one of these avenues.\nAutonomous vehicles employ these applications and technology to accomplish a panoramic view, both\nnear (in their close environment) and far. This implies that computer manufacturers use increasingly\nadvanced processing nodes to meet expanding requirements for efficiency while reducing power and\nfootprint constraints."
}
```

## 5. Gemini API Request

```json
{
  "model": "gemini-2.5-pro",
  "systemInstruction": "You are CiteBite, an AI research assistant specialized in analyzing academic papers.\n\n## YOUR ROLE\nYou help researchers understand and synthesize findings from their paper collection. You will be provided with relevant excerpts from research papers as context.\n\n## CITATION FORMAT (CRITICAL)\n- Use [CITE:N] markers to cite sources (e.g., [CITE:1], [CITE:2])\n- Each number corresponds to the source excerpt provided in the context\n- You MUST cite sources for every factual claim you make\n- If multiple sources support a claim, cite all of them (e.g., [CITE:1][CITE:3])\n\n## RESPONSE STRUCTURE\n1. Lead with the most relevant findings\n2. Support each claim with [CITE:N] citations\n3. When synthesizing across sources, cite all relevant ones\n4. Be specific - include numbers, methods, or conclusions that can be traced to sources\n\n## HANDLING LIMITATIONS\n- If context doesn't contain relevant information: \"Based on the available excerpts, I couldn't find specific information about [topic].\"\n- If only one source is relevant: Acknowledge this and provide what you can\n- If information conflicts: Present both perspectives with their citations\n\nRemember: Every statement must be supported by the provided context using [CITE:N] format.",
  "temperature": 0.2,
  "maxOutputTokens": 4096,
  "contentsCount": 1,
  "userPrompt": "Based on the following research paper excerpts, answer the question.\nUse [CITE:N] markers to cite specific sources (e.g., [CITE:1], [CITE:2]).\n\n## Context from Papers:\n\n[1]\ne autonomous driving of vehicles through technical\nmeans such as environment perception, planning decision-\nmaking, automatic control, etc., in order to improve driving\nsafety, efficiency and comfort. Autonomous driving\ntechnologies are usually categorized into different levels of\nautomation, ranging from partially automated driving to fully\nautomated driving. Using the classification method of the\nSociety of Automotive Engineers (SAE), automated driving\ntechnologies are described by dividing them into 6 levels (L0-\nL5, shown in Table 1).\nDevelopment history: The development of automatic\ndriving technology can be traced back to decades ago, but in\nrecent years has experienced rapid development, from the\ninitial assisted driving system to fully automated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving.\n\n[2]\nautomated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving. \nAssisted driving systems: These mainly include blind spot\nmonitoring, lane keeping assist, adaptive cruise control,\nautomatic emergency braking and other functions. The driver\nremains the primary controller and needs to monitor and\noperate the vehicle at all times. Basic camera, radar and\nultrasonic sensors are used. The aim is to improve driving\nsafety and reduce some of the burden on the driver.\nCorresponds to SAE levels L1 and L2 above. reduces the\nnumber of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages.\n\n[3]\nl\ncannot avoid accidents. Such examples include the Tesla and Volvo XC90, where serious\ninjuries and even deaths have occurred. This is a consequence of rapid urbanization and\nthe demand for mobility. Nowadays, an autonomous vehicle is expected to have an impact\non increasing road safety and thus reduce accidents. All vehicle manufacturers strive to\nachieve the highest level of autonomy. To achieve this, it is necessary to ensure the accurate\ndetection of the environment and safe driving in different scenarios. The authors proposed\na new unified framework for fully autonomous vehicles that integrates multiple modules.\nClothoid was implemented on Hyundai I-30 vehicle with a customized sensory and control\nsystem. The modules used are described in detail in the system architecture. The proposed\nsolution includes modules that take into account safety, i.e., HD mapping, localization,\nenvironment perception, path planning, and control modules.\n\n[4]\ndriving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade .\nNotably, the complexity of ADSs operation in indeterminate environments raises\nthe challenge of diverse weather conditions and a need to account for agent behaviour,\nespecially in busy urban environments, where autonomous vehicles have advantages\nover human drivers . Furthermore, failure to correctly address these challenges has\nled to accidents that undermine public acceptance of ADSs . In the attempt to reflect\nlessons learned from various stakeholders, theSociety of Automotive Engineers(SAE) defined\nsix levels of driving autonomy where levelzerostands for no autonomy and levelsfour\nandfivestand for autonomy where no human interaction is required . Furthermore,\nthe autonomous systems and their design process must comply with functional safety\nrequirements, i.e., ISO26262 .\n\n[5]\nring road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project .\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road. Further large scale automated driving studies were carried in Europe’s Eureka\nAppl. Sci.2022,12, 168. https://doi.org/10.3390/app12010168https://www.mdpi.com/journal/applsci\n\nAppl. Sci.2022,12, 1682 of 24\nproject PROMETHEUS between 1987 and 1995. The project led to the development of\nVITA II by Daimler-Benz, which succeeded in automatically driving on highways .\nSince the first automated driving challenge organized by the US Department of Defense in\n2004—Defense Advanced Research Projects Agency’s(DARPA) Grand Challenge, autonomous\ndriving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade .\n\n[6]\ny. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information. Laws, regulations\nand standards for advanced driver assistance systems are\nbeginning to emerge, providing legal protection for the\npromotion and popularisation of the technology. Significantly\nimproving the user experience, more driving tasks can be\ncompleted by the system under specific conditions.\nFully Automatic Driving: The vehicle is able to complete\nthe driving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process.\n\n[7]\ner of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages.\nAdvanced Driver Assistance: Based on the Assisted\nDriving System, more automated functions are added, such as\nTraffic Jam Assist, Motorway Driving Assist and Automatic\nParking System. The driver still needs to be alert, but in some\ncases the vehicle is able to perform more driving tasks\nautonomously. The addition of laser radar (LiDAR), more\nadvanced camera and radar systems, as well as greater\ncomputing power and software algorithms, further reduces\nthe operational burden on the driver and increases driving\ncomfort and safety. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information.\n\n[8]\n, we are witnessing the growing intelligence of\nvehicles, thanks to recent advancements in embedded systems,\nnavigation, sensors, data acquisition and dissemination, and\nbig data analytics , . It started with assisted-driving\ntechnologies, namely, Advanced Driver-Assistance Systems\n(ADAS), including emergency braking, backup cameras, adap-\ntive cruise control, and self-parking systems . Around the\nworld, the number of ADAS systems rose from 90 million\nunits in 2014 to about 140 million in 2016, a 50% increase in\njust two years . According to the definitions of autonomous\nvehicles laid out by the Society of Automotive Engineers\n(SAE) International, the above systems mainly belong to Level\n1 and Level 2 of automation. Tesla’s Autopilot system also\nfalls in this category . Automotive manufacturers and\ntechnical companies, such as Google, Uber, Tesla, Mobileye,\nare investing heavily on higher levels of driving autonomation.\n\n[9]\nh and Reviews, 2024, 21(01), 2009–2020\n2015\ncruise control, lane-keeping assistance, and automatic emergency braking serve as building blocks for the gradual\nintegration of autonomous functionalities. These systems contribute to enhanced safety by assisting drivers and\nmitigating risks, paving the way for the broader acceptance of autonomous technologies.\nThe development and testing of autonomous systems involve extensive simulations and controlled environments.\nSimulated scenarios allow engineers to expose embedded systems to a wide range of situations, including rare and\ndangerous events, to validate their responses. This approach aids in refining algorithms, improving safety mechanisms,\nand ensuring the robustness of autonomous vehicles before real-world deployment. Enhancements in HMI design focus\non creating intuitive interfaces that facilitate effective communication between the vehicle and its occupants.\n\n[10]\nmated, i.e., the vehicle can handle a few situations (such as lane\nchanging, autonomous emergency braking (AEB)), and the driver should be monitoring\nand ready to take over the vehicle at any instant. Level 4, which includes higher automation\nfeatures, has an automated driving system (ADS) that can handle most dynamic driving\ntasks without human intervention . Ultimately, the vehicles are expected to handle\nall situations and become fully autonomous in SAE level 5. Today, level 2–4 vehicles are\nbeing tested and deployed in the market . For example, Tesla’s level 2 with autopilot\nsystem and level 3 with the fully self-driving mode  are commercially available .\nEven with remarkable advancements in CAV development, it would be unrealistic to\nanticipate zero system failures. It is widely acknowledged that CAVs may not handle all road\nincidents and will depend on human decisions , as the real world can be very uncertain.\n\n[11]\nving. After 2024, fully automatic driving will be realized with more advanced\nfunctions such as unmanned automatic driving and coordinated optimization control of vehicles and\nroads in the urban area.\n\n[12]\ntensive use of vehicle infrastructure, labour cost savings, congestion re-\nduction, environmental benefits and, above all, a reduced number of accidents, of which\n94%(±2.2%) are caused by drivers . Furthermore, the annual consumer and societal\nbenefits of the AVs are estimated to reach $800 billion by 2050 . Nevertheless, further\ndevelopment of automated driving systems relies on the advancements of scientific disci-\nplines and new technologies. While the combination of accumulated knowledge in vehicle\ndynamics, the emergence of deep learning and the availability of new sensor modalities\ncatalysed AVs research, the challenges of fail-operational architectural models and robust\nperception are yet to be solved .\nInitially, the public experienced autonomous driving through the pioneering road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project .\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road.\n\n[13]\nant cost\nfactor . Moreover, the absolute majority of the innovation\nin modern cars is embodied by software –.\nThis new paradigm is a great enabler for more automated\nand autonomous functions. The Society of Automotive En-\ngineers (SAE) classifies the levels of autonomy in 6 levels\n: from no automation (level 0) to full automation under\nall circumstances without any need for a handover of control\n(level 5). Advanced driver-assistance systems (ADAS), which\ntake over much of the driving tasks (under the assumption\nof the possibility of rapid handover to a human driver), are\nalready present in modern high-end cars. There are commercial\nThis work is supported by the Leicester AI Network, through a Research\nNetwork grant awarded by the Leicester Institute for Advanced Studies, the\nRoyal Society Summer Science Exhibition, and Zenzic\nlevel 2 and 3 autonomous vehicles, which take over all driving\nfunctions under predefined circumstances, yet these systems\nstill rely on the the possi\n\n[14]\ncomfort, and efficiency. The analysis begins by\ntracking the historical progression of driver assistance systems, from primitive anti-lock braking systems\nto the advanced ADAS seen in modern vehicles. The focus is on comprehending the innovative\nbreakthroughs that have paved the path for the current status of ADAS.\nThe poll looks into the essential elements and functionality of ADAS, covering everything from simple\nfeatures like adaptive cruise control and lane-keeping guidance to more sophisticated features like\nautomatic emergency braking and pedestrian detection. A thorough examination of the underlying\ntechnology, including as sensors, cameras, radar, and lidar systems, reveals insights into the problems and\nopportunities connected with each.\n\n[15]\nving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process. Comprehensively adopting a\nvariety of sensors, including high-precision LIDAR,\nmillimetre-wave radar, high-definition cameras and high-\nprecision maps, combined with powerful AI algorithms and\ncomputational capabilities, the vehicle can achieve true\ndriverlessness, improve traffic efficiency, reduce traffic\naccidents and provide a convenient way of travelling. L4 and\n\n\n67\nL5, which correspond to SAE levels, are the embodiment of\nmajor breakthroughs in algorithms and computing\ncapabilities, especially the maturity of AI and machine\nlearning technologies, and have far-reaching impacts on\ntraffic management, urban planning, and social and legal\nsystems, including employment, legal responsibilities, and\nethical issues.\nTable 1 Specific information\nHierarchy Specific information\nL0 L0, i.e.\n\n[16]\nased on information\nderived from sensors. The scientific approach to pro-\ngress in this area involves conducting comprehensive\ntests to assess the ability of vehicles to react to vari-\nous conditions. This contributes to improving their\nperformance and increasing reliability. In this con-\ntext, scientific research is emerging as a key driver for\nthe development and improvement of the autonomous\nvehicle industry and making it a necessary part of the\nfuture of transportation .\nThe technology enabling self-driving vehicles\noffers many advantages that will transform the way\nwe commute and transport goods. One of its key\ncomponents is path planning. Enhanced safety is one\nof the principal benefits. Self-driving vehicles elimi-\nnate the possibility of human error-related accidents\nby calculating and choosing the best route while con-\nsidering real-time data on traffic, weather, and road\nconditions.\n\n[17]\nautonomous vehicles\n(George, Baskar & Srikaanth, 2023, Krichen, 2023).\nTo address safety concerns in autonomous driving, there is a notable focus on enhancing sensor redundancy and fusion\ntechniques. By integrating diverse sensor technologies and ensuring multiple layers of sensing capabilities, vehicles can\nbuild a more comprehensive and accurate perception of their environment. This redundancy not only improves the\nreliability of embedded systems but also provides fail-safes in the event of sensor malfunctions. Innovations in ADAS\nplay a pivotal role in bridging the transition between conventional and autonomous driving. Features such as adaptive\n\nWorld Journal of Advanced Research and Reviews, 2024, 21(01), 2009–2020\n2015\ncruise control, lane-keeping assistance, and automatic emergency braking serve as building blocks for the gradual\nintegration of autonomous functionalities.\n\n[18]\nng, etc., vehicle systems at L3 level are able to rely on their\nown sensors to sense the driving environment, but monitoring tasks still need to be led by the human driver, and human driver\nintervention is still required in emergency\nsituations.\nL4\nThe term \"high degree autonomous driving\" means that in limited areas or limited\nenvironments (e.g. fixed parks, closed and semi-closed highways, etc.), the vehicle\ncan fully sense the environment and intervene autonomously in emergencies without the need for any intervention by the\nhuman driver. In Level L4, the vehicle can be free of steering wheel, accelerator and brake pedals, but its application can only\nbe limited to special scenarios and environments.\nL5\nThat is, fully automatic driving, L5 does not require a driver, nor does it require\nanyone to intervene with the steering wheel and throttle, braking, etc., and is not\nlimited to driving in specific scenarios, but can adapt to any scenario and environment of automatic driving.\n2.2.\n\n[19]\nnd of the decade.\nNonetheless, a key to more sustainable progress towards the highest levels of autonomy is\na gradual adoption of the already available technologies, as already accomplished with\nADAS. The passenger vehicle demonstrator for low-speed autonomy addresses this chal-\nlenge and shows that such applications as self-parking and autonomous delivery of goods\nare feasible with the current maturity of the sensors and computing paradigms.\nAnother encouraging research vector is ensuring the security and reliability of sen-\nsor data and SW/HW components. In this respect, we have devised a trust model for\nenhancing fusion that provides the operational status of the integrated components. Fur-\nthermore, the eventual acceptance of autonomous vehicles requires this information to be\nconveniently accessible in real-time via HMI.\n\n[20]\nicles have ADAS built in from the start, which is improved when new vehicle models\nand features are introduced. The devices leverage a range of information sources to provide useful security\nfeatures. Automotive imagery is a combination of excellent imaging sensors that equal and outperform\nthe capabilities of the human retina. This is in the form of 360-degree reach, 3D object quality, clarity in\ndifficult weather and lighting scenarios, and immediate information, that is one of these avenues.\nAutonomous vehicles employ these applications and technology to accomplish a panoramic view, both\nnear (in their close environment) and far. This implies that computer manufacturers use increasingly\nadvanced processing nodes to meet expanding requirements for efficiency while reducing power and\nfootprint constraints.\n\n## Question: tell me about what does full self driving means, and how did it improved until now\n\n## Instructions:\n- Answer based ONLY on the provided context\n- Use [CITE:N] format to cite sources (N is the source number)\n- If information isn't in the context, say so\n- Be specific and cite multiple sources when applicable",
  "conversationHistoryInRequest": []
}
```

## 6. Raw LLM Response

```json
{
  "rawAnswerLength": 4687,
  "rawAnswer": "Based on the provided excerpts, here is a summary of what full self-driving means and how the technology has progressed.\n\n### Defining Full Self-Driving\n\nFull self-driving, or full automation, corresponds to the highest levels of the Society of Automotive Engineers (SAE) classification system, specifically Levels 4 and 5 [CITE:4][CITE:15].\n\n*   **Core Functionality:** At these levels, the vehicle can complete an entire driving task from start to finish without any intervention from a human driver [CITE:6][CITE:15]. The driver becomes a passenger and is no longer required to be involved in the driving process [CITE:6][CITE:15].\n*   **SAE Level 4 (High Automation):** An automated driving system (ADS) can handle most dynamic driving tasks without human intervention, but its application may be limited to specific areas or environments, such as fixed parks or closed highways [CITE:10][CITE:18]. In L4, the vehicle may not have a steering wheel, accelerator, or brake pedals [CITE:18].\n*   **SAE Level 5 (Full Automation):** This is the ultimate goal where the vehicle is expected to handle all situations and become fully autonomous [CITE:10]. L5 automation is not limited to specific scenarios and can adapt to any driving environment without the need for a driver or human intervention [CITE:13][CITE:18].\n\n### Technological Progression to Full Automation\n\nThe development of autonomous driving has progressed through several distinct stages over decades [CITE:1]. Early research includes the \"Alvin\" vehicle in 1985, which achieved autonomy for 4.2 km on a gravel road, and Europe's PROMETHEUS project between 1987 and 1995 [CITE:5][CITE:12]. The technology's evolution is roughly divided into three main stages [CITE:1][CITE:2].\n\n1.  **Assisted Driving Systems (SAE L1-L2):**\n    *   **Function:** This initial stage includes features like blind spot monitoring, adaptive cruise control, lane-keeping assist, and automatic emergency braking [CITE:2][CITE:8][CITE:17].\n    *   **Driver's Role:** The driver remains the primary controller and must monitor the vehicle at all times [CITE:2]. These systems are designed to improve safety and reduce some of the driver's burden [CITE:2].\n    *   **Technology:** This stage uses basic sensors like cameras, radar, and ultrasonic sensors [CITE:2]. Tesla's Autopilot system is categorized at this level [CITE:8][CITE:10].\n\n2.  **Advanced Driver Assistance Systems (ADAS) (SAE L3):**\n    *   **Function:** This stage adds more automated functions, such as Traffic Jam Assist, Motorway Driving Assist, and Automatic Parking [CITE:7].\n    *   **Driver's Role:** The driver still needs to be alert and ready to intervene in emergencies, but the vehicle can perform more driving tasks autonomously under specific conditions [CITE:7][CITE:18].\n    *   **Technology:** This level reflects a significant increase in sensor technology, adding LiDAR, more advanced cameras, and greater computing power to process more environmental information [CITE:7].\n\n3.  **Fully Automatic Driving (SAE L4-L5):**\n    *   **Function:** This stage aims for true driverlessness, where the vehicle handles all driving tasks [CITE:6][CITE:15]. The goals are to improve traffic efficiency and reduce accidents caused by human error [CITE:12][CITE:15][CITE:16].\n    *   **Technology:** This requires a comprehensive suite of sensors, including high-precision LiDAR, millimeter-wave radar, high-definition cameras, and high-precision maps, combined with powerful AI algorithms and computational capabilities [CITE:15].\n\n### Current Status and Challenges\n\nDespite significant advancements, achieving full automation has been challenging.\n\n*   **Current Deployment:** As of today, vehicles at levels 2-4 are being tested and deployed in the market [CITE:10]. Some commercial vehicles are available at level 2 and 3, which take over driving functions under predefined circumstances but still rely on the possibility of a rapid handover to a human driver [CITE:13].\n*   **Delayed Timelines:** Predictions that fully autonomous driving would be available by 2017 were not met, and the goal might be delayed for another decade [CITE:4][CITE:5]. One prediction suggests it will be realized after 2024 [CITE:11].\n*   **Remaining Hurdles:** Challenges include ensuring safe operation in diverse weather conditions, accounting for unpredictable agent behavior in busy urban areas, and solving issues related to fail-operational architectural models and robust perception [CITE:4][CITE:12]. Accidents involving autonomous systems have undermined public acceptance, highlighting the need for enhanced safety, sensor redundancy, and fusion techniques [CITE:3][CITE:4][CITE:17]."
}
```

## 7. Parsed Citations

```json
{
  "citedIndices": [3, 14, 5, 9, 17, 12, 0, 4, 11, 1, 7, 16, 6, 15, 10, 2],
  "citedChunks": [
    {
      "index": 3,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "contentPreview": "driving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade [6,7]...."
    },
    {
      "index": 14,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "contentPreview": "ving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process...."
    },
    {
      "index": 5,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "contentPreview": "y. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information...."
    },
    {
      "index": 9,
      "paperId": "a56a5a4affe2dd34904009027569eb5f6f142bd9",
      "contentPreview": "mated, i.e., the vehicle can handle a few situations (such as lane\nchanging, autonomous emergency braking (AEB)), and the driver should be monitoring\nand ready to take over the vehicle at any instant...."
    },
    {
      "index": 17,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "contentPreview": "ng, etc., vehicle systems at L3 level are able to rely on their\nown sensors to sense the driving environment, but monitoring tasks still need to be led by the human driver, and human driver\ninterventi..."
    },
    {
      "index": 12,
      "paperId": "a32f9566c196a9ecff40f89d79b5a124a3e06750",
      "contentPreview": "ant cost\nfactor [2]. Moreover, the absolute majority of the innovation\nin modern cars is embodied by software [2]–[4].\nThis new paradigm is a great enabler for more automated\nand autonomous functions...."
    },
    {
      "index": 0,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "contentPreview": "e autonomous driving of vehicles through technical\nmeans such as environment perception, planning decision-\nmaking, automatic control, etc., in order to improve driving\nsafety, efficiency and comfort...."
    },
    {
      "index": 4,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "contentPreview": "ring road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project [4].\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road...."
    },
    {
      "index": 11,
      "paperId": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "contentPreview": "tensive use of vehicle infrastructure, labour cost savings, congestion re-\nduction, environmental benefits and, above all, a reduced number of accidents, of which\n94%(±2.2%) are caused by drivers [1]...."
    },
    {
      "index": 1,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "contentPreview": "automated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving...."
    },
    {
      "index": 7,
      "paperId": "2a6459d12bc80b49bb1b802be38a29df0364b67a",
      "contentPreview": ", we are witnessing the growing intelligence of\nvehicles, thanks to recent advancements in embedded systems,\nnavigation, sensors, data acquisition and dissemination, and\nbig data analytics [11], [12]...."
    },
    {
      "index": 16,
      "paperId": "feb2333acd3123f1e77cbd32a284391a54585268",
      "contentPreview": "autonomous vehicles\n(George, Baskar & Srikaanth, 2023, Krichen, 2023).\nTo address safety concerns in autonomous driving, there is a notable focus on enhancing sensor redundancy and fusion\ntechniques. ..."
    },
    {
      "index": 6,
      "paperId": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "contentPreview": "er of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages...."
    },
    {
      "index": 15,
      "paperId": "696771f18ad59f6932c3c8090b7bf7855ecb5518",
      "contentPreview": "ased on information\nderived from sensors. The scientific approach to pro-\ngress in this area involves conducting comprehensive\ntests to assess the ability of vehicles to react to vari-\nous conditions...."
    },
    {
      "index": 10,
      "paperId": "a1d024ad226b66302f6f1624ef411e023aed2289",
      "contentPreview": "ving. After 2024, fully automatic driving will be realized with more advanced\nfunctions such as unmanned automatic driving and coordinated optimization control of vehicles and\nroads in the urban area...."
    },
    {
      "index": 2,
      "paperId": "818290bcede2ae9b1d29c9d126008b9e7cd4d353",
      "contentPreview": "l\ncannot avoid accidents. Such examples include the Tesla and Volvo XC90, where serious\ninjuries and even deaths have occurred. This is a consequence of rapid urbanization and\nthe demand for mobility...."
    }
  ]
}
```

## 8. Final Response

```json
{
  "answerLength": 4679,
  "answer": "Based on the provided excerpts, here is a summary of what full self-driving means and how the technology has progressed.\n\n### Defining Full Self-Driving\n\nFull self-driving, or full automation, corresponds to the highest levels of the Society of Automotive Engineers (SAE) classification system, specifically Levels 4 and 5 [CITE:1][CITE:2].\n\n*   **Core Functionality:** At these levels, the vehicle can complete an entire driving task from start to finish without any intervention from a human driver [CITE:3][CITE:2]. The driver becomes a passenger and is no longer required to be involved in the driving process [CITE:3][CITE:2].\n*   **SAE Level 4 (High Automation):** An automated driving system (ADS) can handle most dynamic driving tasks without human intervention, but its application may be limited to specific areas or environments, such as fixed parks or closed highways [CITE:4][CITE:5]. In L4, the vehicle may not have a steering wheel, accelerator, or brake pedals [CITE:5].\n*   **SAE Level 5 (Full Automation):** This is the ultimate goal where the vehicle is expected to handle all situations and become fully autonomous [CITE:4]. L5 automation is not limited to specific scenarios and can adapt to any driving environment without the need for a driver or human intervention [CITE:6][CITE:5].\n\n### Technological Progression to Full Automation\n\nThe development of autonomous driving has progressed through several distinct stages over decades [CITE:7]. Early research includes the \"Alvin\" vehicle in 1985, which achieved autonomy for 4.2 km on a gravel road, and Europe's PROMETHEUS project between 1987 and 1995 [CITE:8][CITE:9]. The technology's evolution is roughly divided into three main stages [CITE:7][CITE:10].\n\n1.  **Assisted Driving Systems (SAE L1-L2):**\n    *   **Function:** This initial stage includes features like blind spot monitoring, adaptive cruise control, lane-keeping assist, and automatic emergency braking [CITE:10][CITE:11][CITE:12].\n    *   **Driver's Role:** The driver remains the primary controller and must monitor the vehicle at all times [CITE:10]. These systems are designed to improve safety and reduce some of the driver's burden [CITE:10].\n    *   **Technology:** This stage uses basic sensors like cameras, radar, and ultrasonic sensors [CITE:10]. Tesla's Autopilot system is categorized at this level [CITE:11][CITE:4].\n\n2.  **Advanced Driver Assistance Systems (ADAS) (SAE L3):**\n    *   **Function:** This stage adds more automated functions, such as Traffic Jam Assist, Motorway Driving Assist, and Automatic Parking [CITE:13].\n    *   **Driver's Role:** The driver still needs to be alert and ready to intervene in emergencies, but the vehicle can perform more driving tasks autonomously under specific conditions [CITE:13][CITE:5].\n    *   **Technology:** This level reflects a significant increase in sensor technology, adding LiDAR, more advanced cameras, and greater computing power to process more environmental information [CITE:13].\n\n3.  **Fully Automatic Driving (SAE L4-L5):**\n    *   **Function:** This stage aims for true driverlessness, where the vehicle handles all driving tasks [CITE:3][CITE:2]. The goals are to improve traffic efficiency and reduce accidents caused by human error [CITE:9][CITE:2][CITE:14].\n    *   **Technology:** This requires a comprehensive suite of sensors, including high-precision LiDAR, millimeter-wave radar, high-definition cameras, and high-precision maps, combined with powerful AI algorithms and computational capabilities [CITE:2].\n\n### Current Status and Challenges\n\nDespite significant advancements, achieving full automation has been challenging.\n\n*   **Current Deployment:** As of today, vehicles at levels 2-4 are being tested and deployed in the market [CITE:4]. Some commercial vehicles are available at level 2 and 3, which take over driving functions under predefined circumstances but still rely on the possibility of a rapid handover to a human driver [CITE:6].\n*   **Delayed Timelines:** Predictions that fully autonomous driving would be available by 2017 were not met, and the goal might be delayed for another decade [CITE:1][CITE:8]. One prediction suggests it will be realized after 2024 [CITE:15].\n*   **Remaining Hurdles:** Challenges include ensuring safe operation in diverse weather conditions, accounting for unpredictable agent behavior in busy urban areas, and solving issues related to fail-operational architectural models and robust perception [CITE:1][CITE:9]. Accidents involving autonomous systems have undermined public acceptance, highlighting the need for enhanced safety, sensor redundancy, and fusion techniques [CITE:16][CITE:1][CITE:12].",
  "groundingChunksCount": 16,
  "groundingChunks": [
    {
      "index": 0,
      "paper_id": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "textPreview": "driving has become a lasting research topic. Despite famous claims that fully autonomous\ndriving will be available in 2017, the set goal was not achieved and might be delayed for\nanother decade [6,7]...."
    },
    {
      "index": 1,
      "paper_id": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "textPreview": "ving task from start to finish completely autonomously\nwithout the intervention of a human driver. The driver can\nbecome a complete passenger and no longer needs to be\ninvolved in the driving process...."
    },
    {
      "index": 2,
      "paper_id": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "textPreview": "y. L3, which corresponds to the SAE level,\nreflects a significant increase in sensor technology and data\nprocessing capabilities, enabling vehicles to sense and\nprocess more environmental information...."
    },
    {
      "index": 3,
      "paper_id": "a56a5a4affe2dd34904009027569eb5f6f142bd9",
      "textPreview": "mated, i.e., the vehicle can handle a few situations (such as lane\nchanging, autonomous emergency braking (AEB)), and the driver should be monitoring\nand ready to take over the vehicle at any instant...."
    },
    {
      "index": 4,
      "paper_id": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "textPreview": "ng, etc., vehicle systems at L3 level are able to rely on their\nown sensors to sense the driving environment, but monitoring tasks still need to be led by the human driver, and human driver\ninterventi..."
    },
    {
      "index": 5,
      "paper_id": "a32f9566c196a9ecff40f89d79b5a124a3e06750",
      "textPreview": "ant cost\nfactor [2]. Moreover, the absolute majority of the innovation\nin modern cars is embodied by software [2]–[4].\nThis new paradigm is a great enabler for more automated\nand autonomous functions...."
    },
    {
      "index": 6,
      "paper_id": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "textPreview": "e autonomous driving of vehicles through technical\nmeans such as environment perception, planning decision-\nmaking, automatic control, etc., in order to improve driving\nsafety, efficiency and comfort...."
    },
    {
      "index": 7,
      "paper_id": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "textPreview": "ring road-\nfollowing vehicle Alvin in 1985 developed in the Autonomous Land Vehicle (ALV) project [4].\nThe simple “Red minus Blue” segmentation algorithm achieved autonomy for 4.2 km on a\ngravel road...."
    },
    {
      "index": 8,
      "paper_id": "de0e502e7f7c09f5639fdfd24847557efc1f1278",
      "textPreview": "tensive use of vehicle infrastructure, labour cost savings, congestion re-\nduction, environmental benefits and, above all, a reduced number of accidents, of which\n94%(±2.2%) are caused by drivers [1]...."
    },
    {
      "index": 9,
      "paper_id": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "textPreview": "automated driving,\nautomatic driving technology has made great breakthroughs.\nIt is roughly divided into three stages: assisted driving system,\nadvanced driver assistance system and automatic driving...."
    },
    {
      "index": 10,
      "paper_id": "2a6459d12bc80b49bb1b802be38a29df0364b67a",
      "textPreview": ", we are witnessing the growing intelligence of\nvehicles, thanks to recent advancements in embedded systems,\nnavigation, sensors, data acquisition and dissemination, and\nbig data analytics [11], [12]...."
    },
    {
      "index": 11,
      "paper_id": "feb2333acd3123f1e77cbd32a284391a54585268",
      "textPreview": "autonomous vehicles\n(George, Baskar & Srikaanth, 2023, Krichen, 2023).\nTo address safety concerns in autonomous driving, there is a notable focus on enhancing sensor redundancy and fusion\ntechniques. ..."
    },
    {
      "index": 12,
      "paper_id": "bb45699d5d88810b34db9381350c7283fd18d9d6",
      "textPreview": "er of traffic accidents, especially collisions at low\nspeeds and stopping, gradually allows users to accept and\ntrust autonomous driving technology, and lays the\ngroundwork for future advanced stages...."
    },
    {
      "index": 13,
      "paper_id": "696771f18ad59f6932c3c8090b7bf7855ecb5518",
      "textPreview": "ased on information\nderived from sensors. The scientific approach to pro-\ngress in this area involves conducting comprehensive\ntests to assess the ability of vehicles to react to vari-\nous conditions...."
    },
    {
      "index": 14,
      "paper_id": "a1d024ad226b66302f6f1624ef411e023aed2289",
      "textPreview": "ving. After 2024, fully automatic driving will be realized with more advanced\nfunctions such as unmanned automatic driving and coordinated optimization control of vehicles and\nroads in the urban area...."
    },
    {
      "index": 15,
      "paper_id": "818290bcede2ae9b1d29c9d126008b9e7cd4d353",
      "textPreview": "l\ncannot avoid accidents. Such examples include the Tesla and Volvo XC90, where serious\ninjuries and even deaths have occurred. This is a consequence of rapid urbanization and\nthe demand for mobility...."
    }
  ],
  "groundingSupportsCount": 45,
  "groundingSupports": [
    {
      "segment": {
        "startIndex": 323,
        "endIndex": 331,
        "text": "[CITE:1]"
      },
      "groundingChunkIndices": [0]
    },
    {
      "segment": {
        "startIndex": 331,
        "endIndex": 339,
        "text": "[CITE:2]"
      },
      "groundingChunkIndices": [1]
    },
    {
      "segment": {
        "startIndex": 501,
        "endIndex": 509,
        "text": "[CITE:3]"
      },
      "groundingChunkIndices": [2]
    },
    {
      "segment": {
        "startIndex": 509,
        "endIndex": 517,
        "text": "[CITE:2]"
      },
      "groundingChunkIndices": [1]
    },
    {
      "segment": {
        "startIndex": 614,
        "endIndex": 622,
        "text": "[CITE:3]"
      },
      "groundingChunkIndices": [2]
    },
    {
      "segment": {
        "startIndex": 622,
        "endIndex": 630,
        "text": "[CITE:2]"
      },
      "groundingChunkIndices": [1]
    },
    {
      "segment": {
        "startIndex": 880,
        "endIndex": 888,
        "text": "[CITE:4]"
      },
      "groundingChunkIndices": [3]
    },
    {
      "segment": {
        "startIndex": 888,
        "endIndex": 896,
        "text": "[CITE:5]"
      },
      "groundingChunkIndices": [4]
    },
    {
      "segment": {
        "startIndex": 977,
        "endIndex": 985,
        "text": "[CITE:5]"
      },
      "groundingChunkIndices": [4]
    },
    {
      "segment": {
        "startIndex": 1135,
        "endIndex": 1143,
        "text": "[CITE:4]"
      },
      "groundingChunkIndices": [3]
    },
    {
      "segment": {
        "startIndex": 1289,
        "endIndex": 1297,
        "text": "[CITE:6]"
      },
      "groundingChunkIndices": [5]
    },
    {
      "segment": {
        "startIndex": 1297,
        "endIndex": 1305,
        "text": "[CITE:5]"
      },
      "groundingChunkIndices": [4]
    },
    {
      "segment": {
        "startIndex": 1456,
        "endIndex": 1464,
        "text": "[CITE:7]"
      },
      "groundingChunkIndices": [6]
    },
    {
      "segment": {
        "startIndex": 1626,
        "endIndex": 1634,
        "text": "[CITE:8]"
      },
      "groundingChunkIndices": [7]
    },
    {
      "segment": {
        "startIndex": 1634,
        "endIndex": 1642,
        "text": "[CITE:9]"
      },
      "groundingChunkIndices": [8]
    },
    {
      "segment": {
        "startIndex": 1713,
        "endIndex": 1721,
        "text": "[CITE:7]"
      },
      "groundingChunkIndices": [6]
    },
    {
      "segment": {
        "startIndex": 1721,
        "endIndex": 1730,
        "text": "[CITE:10]"
      },
      "groundingChunkIndices": [9]
    },
    {
      "segment": {
        "startIndex": 1944,
        "endIndex": 1953,
        "text": "[CITE:10]"
      },
      "groundingChunkIndices": [9]
    },
    {
      "segment": {
        "startIndex": 1953,
        "endIndex": 1962,
        "text": "[CITE:11]"
      },
      "groundingChunkIndices": [10]
    },
    {
      "segment": {
        "startIndex": 1962,
        "endIndex": 1971,
        "text": "[CITE:12]"
      },
      "groundingChunkIndices": [11]
    },
    {
      "segment": {
        "startIndex": 2084,
        "endIndex": 2093,
        "text": "[CITE:10]"
      },
      "groundingChunkIndices": [9]
    },
    {
      "segment": {
        "startIndex": 2179,
        "endIndex": 2188,
        "text": "[CITE:10]"
      },
      "groundingChunkIndices": [9]
    },
    {
      "segment": {
        "startIndex": 2288,
        "endIndex": 2297,
        "text": "[CITE:10]"
      },
      "groundingChunkIndices": [9]
    },
    {
      "segment": {
        "startIndex": 2353,
        "endIndex": 2362,
        "text": "[CITE:11]"
      },
      "groundingChunkIndices": [10]
    },
    {
      "segment": {
        "startIndex": 2362,
        "endIndex": 2370,
        "text": "[CITE:4]"
      },
      "groundingChunkIndices": [3]
    },
    {
      "segment": {
        "startIndex": 2572,
        "endIndex": 2581,
        "text": "[CITE:13]"
      },
      "groundingChunkIndices": [12]
    },
    {
      "segment": {
        "startIndex": 2770,
        "endIndex": 2779,
        "text": "[CITE:13]"
      },
      "groundingChunkIndices": [12]
    },
    {
      "segment": {
        "startIndex": 2779,
        "endIndex": 2787,
        "text": "[CITE:5]"
      },
      "groundingChunkIndices": [4]
    },
    {
      "segment": {
        "startIndex": 2985,
        "endIndex": 2994,
        "text": "[CITE:13]"
      },
      "groundingChunkIndices": [12]
    },
    {
      "segment": {
        "startIndex": 3149,
        "endIndex": 3157,
        "text": "[CITE:3]"
      },
      "groundingChunkIndices": [2]
    },
    {
      "segment": {
        "startIndex": 3157,
        "endIndex": 3165,
        "text": "[CITE:2]"
      },
      "groundingChunkIndices": [1]
    },
    {
      "segment": {
        "startIndex": 3254,
        "endIndex": 3262,
        "text": "[CITE:9]"
      },
      "groundingChunkIndices": [8]
    },
    {
      "segment": {
        "startIndex": 3262,
        "endIndex": 3270,
        "text": "[CITE:2]"
      },
      "groundingChunkIndices": [1]
    },
    {
      "segment": {
        "startIndex": 3270,
        "endIndex": 3279,
        "text": "[CITE:14]"
      },
      "groundingChunkIndices": [13]
    },
    {
      "segment": {
        "startIndex": 3526,
        "endIndex": 3534,
        "text": "[CITE:2]"
      },
      "groundingChunkIndices": [1]
    },
    {
      "segment": {
        "startIndex": 3763,
        "endIndex": 3771,
        "text": "[CITE:4]"
      },
      "groundingChunkIndices": [3]
    },
    {
      "segment": {
        "startIndex": 3967,
        "endIndex": 3975,
        "text": "[CITE:6]"
      },
      "groundingChunkIndices": [5]
    },
    {
      "segment": {
        "startIndex": 4136,
        "endIndex": 4144,
        "text": "[CITE:1]"
      },
      "groundingChunkIndices": [0]
    },
    {
      "segment": {
        "startIndex": 4144,
        "endIndex": 4152,
        "text": "[CITE:8]"
      },
      "groundingChunkIndices": [7]
    },
    {
      "segment": {
        "startIndex": 4209,
        "endIndex": 4218,
        "text": "[CITE:15]"
      },
      "groundingChunkIndices": [14]
    },
    {
      "segment": {
        "startIndex": 4476,
        "endIndex": 4484,
        "text": "[CITE:1]"
      },
      "groundingChunkIndices": [0]
    },
    {
      "segment": {
        "startIndex": 4484,
        "endIndex": 4492,
        "text": "[CITE:9]"
      },
      "groundingChunkIndices": [8]
    },
    {
      "segment": {
        "startIndex": 4652,
        "endIndex": 4661,
        "text": "[CITE:16]"
      },
      "groundingChunkIndices": [15]
    },
    {
      "segment": {
        "startIndex": 4661,
        "endIndex": 4669,
        "text": "[CITE:1]"
      },
      "groundingChunkIndices": [0]
    },
    {
      "segment": {
        "startIndex": 4669,
        "endIndex": 4678,
        "text": "[CITE:12]"
      },
      "groundingChunkIndices": [11]
    }
  ]
}
```

---

# End of Trace

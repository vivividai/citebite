# CiteBite (ResearchGPT) - MVP 제품 기획서

**서비스 정식 명칭**: CiteBite

## 📋 목차

1. [제품 개요](#1-제품-개요)
2. [핵심 기능](#2-핵심-기능)
3. [사용자 플로우](#3-사용자-플로우)
4. [화면 구성](#4-화면-구성)
5. [기능 상세 명세](#5-기능-상세-명세)
6. [데이터 구조](#6-데이터-구조)
7. [UX 가이드라인](#7-ux-가이드라인)
8. [성공 지표](#8-성공-지표)
9. [개발 로드맵](#9-개발-로드맵)

---

## 1. 제품 개요

**제품명**: CiteBite (개발명: ResearchGPT)

### 1.1 비전

연구자가 특정 주제의 최신 논문들과 자연스럽게 대화하며, 연구 아이디어를 발전시키고 검증할 수 있는 개인 맞춤형 AI 연구 어시스턴트

### 1.2 핵심 가치

- **자동화된 논문 수집**: 검색부터 벡터화까지 자동 처리
- **근거 기반 대화**: 모든 답변에 논문 출처 명시
- **지속적인 학습**: 대화 기록 저장으로 맥락 유지
- **커뮤니티 시너지**: 공개 컬렉션 공유로 중복 작업 제거

### 1.3 타겟 사용자

- 대학원생 및 박사과정 연구자
- 산업계 R&D 연구원
- 특정 분야 최신 동향을 파악하려는 전문가

---

## 2. 핵심 기능

### 2.1 기능 맵

```
CiteBite
├── 컬렉션 관리
│   ├── 컬렉션 생성
│   │   ├── 자동 논문 수집 (Open Access)
│   │   └── 수동 PDF 업로드
│   ├── 컬렉션 업데이트 (신규 논문 추가)
│   └── 컬렉션 공유 설정
│
├── AI 대화
│   ├── 논문 기반 질의응답
│   ├── 대화 기록 저장/이어하기
│   └── 문장 수준 인용 표시
│
└── 인사이트 대시보드
    ├── 연구 동향 요약
    ├── Top 논문 자동 추출
    └── 최근 트렌드 분석
```

### 2.2 MVP 포함 기능

✅ 컬렉션 생성 및 관리
✅ Open Access PDF 자동 수집
✅ **수동 PDF 업로드** (Non-Open Access)
✅ AI 대화 (RAG 기반)
✅ **대화 기록 저장 및 이어하기**
✅ **컬렉션 업데이트 (신규 논문)**
✅ **자동 인사이트 생성**
✅ 공개 컬렉션 공유

### 2.3 MVP 제외 기능

❌ 논문 간 관계 시각화
❌ 메모/북마크
❌ 논문 비교 분석
❌ 팀 협업
❌ 인용문 자동 생성

---

## 3. 사용자 플로우

### 3.1 신규 사용자 온보딩

```
START
  ↓
[회원가입/로그인]
  ↓
[환영 화면]
- "첫 연구 컬렉션을 만들어보세요"
- 예시: "generative AI", "cancer immunotherapy"
  ↓
[컬렉션 생성 화면]
- 연구 주제 입력: "transformer architecture"
- 필터 설정: 2020년 이후, 최소 인용 10회 이상
  ↓
[검색 중...]
"💡 127개 관련 논문을 찾았습니다"
"📄 42개는 Open Access PDF가 있습니다"
"⏳ 백그라운드에서 다운로드 중입니다..."
  ↓
[컬렉션 준비 완료!]
"✅ 컬렉션 'Transformer 연구'가 준비되었습니다"
  ↓
[인사이트 대시보드 자동 생성]
- 이 분야 3가지 주요 연구 흐름
- 가장 영향력 있는 논문 Top 5
- 최근 1년간 트렌드
  ↓
[AI 대화 시작]
"안녕하세요! Transformer 연구에 대해 무엇이든 물어보세요 💬"
```

### 3.2 기존 사용자 재방문

```
START
  ↓
[로그인]
  ↓
[홈 화면]
- 내 컬렉션 목록 (카드 형태)
- 최근 대화 미리보기
  ↓
[컬렉션 선택]
  ↓
[대화 화면]
- 이전 대화 기록 표시
- "이전 대화 이어서 하기" / "새 대화 시작하기"
  ↓
[대화 진행]
```

### 3.3 Non-Open Access 논문 추가

```
[컬렉션 상세 화면]
  ↓
[논문 리스트]
- 논문 X: "Open Access 아님" 표시
  ↓
[논문 카드 클릭]
  ↓
[논문 상세 팝업]
"이 논문은 Open Access가 아닙니다"
[PDF 직접 업로드] 버튼
  ↓
[파일 선택]
  ↓
[업로드 중...]
"PDF를 분석하고 벡터화하는 중입니다..."
  ↓
[완료]
"✅ 논문이 추가되었습니다. 이제 대화에서 참조할 수 있습니다."
```

### 3.4 컬렉션 업데이트

```
[컬렉션 상세 화면]
  ↓
[헤더의 "새 논문 확인" 버튼 클릭]
  ↓
[검색 중...]
"🔍 2024년 11월 이후 신규 논문 확인 중..."
  ↓
[결과 표시]
"📌 5개의 신규 논문을 발견했습니다"
[논문 리스트 미리보기]
- 논문 A (Open Access ✓)
- 논문 B (Open Access ✓)
- 논문 C (구독 필요)
  ↓
[선택 옵션]
☑️ 모든 Open Access 논문 자동 추가
☑️ 수동 선택 (개별 체크박스)
  ↓
[추가 버튼]
  ↓
[백그라운드 처리]
"⏳ 신규 논문을 추가하는 중입니다..."
  ↓
[완료]
"✅ 3개 논문이 추가되었습니다"
[인사이트 대시보드 자동 업데이트]
```

---

## 4. 화면 구성

### 4.1 전체 화면 맵

```
┌─────────────────────────────────────┐
│         네비게이션 바               │
│ [로고] 컬렉션 | 공개 | 프로필       │
└─────────────────────────────────────┘

1. 홈 화면
2. 컬렉션 생성 화면
3. 컬렉션 상세 화면
   ├── 인사이트 대시보드 탭
   ├── 논문 리스트 탭
   └── AI 대화 탭
4. 공개 컬렉션 탐색 화면
```

### 4.2 홈 화면

```
┌─────────────────────────────────────┐
│         내 연구 컬렉션              │
│                                     │
│  ┌──────────────┐  ┌──────────────┐ │
│  │ Transformer  │  │ Cancer       │ │
│  │ Architecture │  │ Immuno...    │ │
│  │              │  │              │ │
│  │ 42개 논문    │  │ 28개 논문    │ │
│  │ 18개 대화    │  │ 12개 대화    │ │
│  │              │  │              │ │
│  │ 최근: 2일전  │  │ 최근: 1주전  │ │
│  └──────────────┘  └──────────────┘ │
│                                     │
│  ┌────────────────────────────────┐ │
│  │  + 새 컬렉션 만들기            │ │
│  └────────────────────────────────┘ │
│                                     │
│        공개 컬렉션 둘러보기         │
│  [인기 컬렉션] [최신 컬렉션]        │
└─────────────────────────────────────┘
```

### 4.3 컬렉션 생성 화면

```
┌─────────────────────────────────────┐
│   새 연구 컬렉션 만들기             │
│                                     │
│  컬렉션 이름                        │
│  ┌────────────────────────────────┐ │
│  │ Transformer Architecture       │ │
│  └────────────────────────────────┘ │
│                                     │
│  연구 주제/키워드                   │
│  ┌────────────────────────────────┐ │
│  │ "attention mechanism" OR       │ │
│  │ "transformer architecture"     │ │
│  └────────────────────────────────┘ │
│                                     │
│  고급 필터 (선택사항) ▼             │
│  ┌────────────────────────────────┐ │
│  │ 출판 연도: [2020] - [2024]     │ │
│  │ 최소 인용 수: [10]             │ │
│  │ ☑️ Open Access만               │ │
│  └────────────────────────────────┘ │
│                                     │
│  컬렉션 공개 설정                   │
│  ◉ 비공개  ○ 공개                   │
│                                     │
│        [컬렉션 만들기]              │
└─────────────────────────────────────┘
```

### 4.4 컬렉션 상세 화면 - 인사이트 탭 (기본)

```
┌─────────────────────────────────────┐
│  Transformer Architecture           │
│  [인사이트] [논문 42] [대화 18]     │
│  [새 논문 확인] [설정 ⚙️]           │
├─────────────────────────────────────┤
│                                     │
│  🔥 이 분야 3가지 주요 연구 흐름    │
│  ┌────────────────────────────────┐ │
│  │ 1. 효율적인 Attention 메커니즘 │ │
│  │    → Linear Attention, Flash...│ │
│  │                                │ │
│  │ 2. Long Context 처리           │ │
│  │    → Sparse Attention, Memor...│ │
│  │                                │ │
│  │ 3. 멀티모달 확장               │ │
│  │    → Vision Transformer, ...   │ │
│  └────────────────────────────────┘ │
│                                     │
│  ⭐ 가장 영향력 있는 논문 Top 5     │
│  ┌────────────────────────────────┐ │
│  │ 1. Attention Is All You Need   │ │
│  │    Vaswani et al. (2017)       │ │
│  │    📊 12,450 인용              │ │
│  │                                │ │
│  │ 2. BERT: Pre-training of Deep..│ │
│  │    Devlin et al. (2018)        │ │
│  │    📊 8,234 인용               │ │
│  └────────────────────────────────┘ │
│                                     │
│  📈 최근 1년 트렌드 변화            │
│  ┌────────────────────────────────┐ │
│  │ • Mixture of Experts 급증      │ │
│  │ • Efficient Training 방법론    │ │
│  │ • State Space Models 등장      │ │
│  └────────────────────────────────┘ │
│                                     │
│  💡 놓칠 수 있는 연구 방향          │
│  ┌────────────────────────────────┐ │
│  │ "최근 논문들은 Attention의 계산│ │
│  │  복잡도를 줄이는 데 집중하고   │ │
│  │  있지만, 해석 가능성에 대한    │ │
│  │  연구는 상대적으로 부족합니다" │ │
│  └────────────────────────────────┘ │
│                                     │
│      [AI와 대화 시작하기]           │
└─────────────────────────────────────┘
```

### 4.5 컬렉션 상세 화면 - 논문 리스트 탭

```
┌─────────────────────────────────────┐
│  Transformer Architecture           │
│  [인사이트] [논문 42] [대화 18]     │
│                                     │
├──────────┬──────────────────────────┤
│ 필터     │  논문 리스트             │
│          │                          │
│ 정렬     │ ┌──────────────────────┐ │
│ ▼ 인용순 │ │ Attention Is All You │ │
│ ○ 최신순 │ │ Vaswani et al. 2017  │ │
│ ○ 관련도 │ │ 📊 12,450 인용       │ │
│          │ │ ✅ Open Access       │ │
│ 연도     │ │ [상세보기] [PDF]     │ │
│ □ 2024   │ └──────────────────────┘ │
│ □ 2023   │                          │
│ ☑️ 2022  │ ┌──────────────────────┐ │
│ ☑️ 2021  │ │ Efficient Attention: │ │
│          │ │ Rabe & Staats 2022   │ │
│ 상태     │ │ 📊 234 인용          │ │
│ ☑️ PDF   │ │ ⚠️ Open Access 아님  │ │
│ □ No PDF │ │ [PDF 업로드] [상세]  │ │
│          │ └──────────────────────┘ │
│ [검색]   │                          │
│ ┌──────┐ │ ┌──────────────────────┐ │
│ │      │ │ │ FlashAttention:      │ │
│ └──────┘ │ │ Dao et al. 2022      │ │
│          │ │ 📊 892 인용          │ │
│          │ │ ✅ Open Access       │ │
│          │ │ [상세보기] [PDF]     │ │
│          │ └──────────────────────┘ │
└──────────┴──────────────────────────┘
```

### 4.6 컬렉션 상세 화면 - AI 대화 탭

```
┌─────────────────────────────────────┐
│  Transformer Architecture           │
│  [인사이트] [논문 42] [대화 18]     │
│                                     │
├─────────────────────────────────────┤
│  대화 기록                          │
│  ┌─────────────────────────────┐    │
│  │ 새 대화 | 이전 대화 (18개) ▼│    │
│  └─────────────────────────────┘    │
│                                     │
│  [이전 대화 선택 시 드롭다운]       │
│  - 2024.11.14: "Attention 효율성에..│
│  - 2024.11.10: "최신 MoE 연구는..." │
│                                     │
├─────────────────────────────────────┤
│  💬 대화 영역                       │
│                                     │
│  🧑 이 분야에서 Attention 계산량을  │
│     줄이는 최신 방법은?             │
│                                     │
│  🤖 최근 연구들은 주로 세 가지      │
│     접근법을 사용합니다:            │
│                                     │
│     1. **Linear Attention**         │
│     [1] Attention의 복잡도를 O(N²)  │
│     에서 O(N)으로 줄입니다.         │
│                                     │
│     2. **Sparse Attention**         │
│     [2,3] 중요한 토큰만 선택적으로  │
│     처리합니다.                     │
│                                     │
│     3. **Flash Attention**          │
│     [4] GPU 메모리 최적화를 통해... │
│                                     │
│     📚 참조 논문:                   │
│     [1] "Transformers are RNNs"     │
│         (Katharopoulos 2020)        │
│     [2] "Longformer" (Beltagy 2020) │
│     [3] "Sparse Transformer"        │
│         (Child 2019)                │
│     [4] "FlashAttention" (Dao 2022) │
│                                     │
├─────────────────────────────────────┤
│  💡 제안 질문:                      │
│  • 이 방법들의 성능 비교는?         │
│  • 실제 구현 시 주의사항은?         │
│  • 최근 트렌드는 어느 쪽인가요?     │
│                                     │
│  ┌─────────────────────────────┐    │
│  │ 메시지를 입력하세요...      │    │
│  │                      [전송] │    │
│  └─────────────────────────────┘    │
└─────────────────────────────────────┘
```

### 4.7 논문 상세 팝업 (Non-Open Access)

```
┌─────────────────────────────────────┐
│  Efficient Attention Mechanisms     │
│  Rabe & Staats, 2022                │
├─────────────────────────────────────┤
│                                     │
│  📊 234회 인용                      │
│  🏛️ ICML 2022                       │
│  👥 저자: Michael Rabe, Christia... │
│                                     │
│  📝 초록                            │
│  ┌────────────────────────────────┐ │
│  │ We present a novel approach to │ │
│  │ reduce the computational cost..│ │
│  └────────────────────────────────┘ │
│                                     │
│  ⚠️ 이 논문은 Open Access가 아닙니다│
│                                     │
│  PDF를 직접 업로드하면 AI 대화에서  │
│  이 논문을 참조할 수 있습니다.      │
│                                     │
│  ┌────────────────────────────────┐ │
│  │  📄 PDF 파일 업로드            │ │
│  │                                │ │
│  │  [파일 선택] 또는 드래그&드롭  │ │
│  └────────────────────────────────┘ │
│                                     │
│  또는                               │
│                                     │
│  🔗 [Semantic Scholar에서 보기]     │
│  🔗 [출판사 페이지에서 보기]        │
│                                     │
│                    [닫기]           │
└─────────────────────────────────────┘
```

### 4.8 공개 컬렉션 탐색 화면

```
┌─────────────────────────────────────┐
│        공개 컬렉션 둘러보기         │
│                                     │
│  [인기순] [최신순] [분야별]         │
│                                     │
│  🔥 인기 컬렉션                     │
│  ┌──────────────┐  ┌──────────────┐ │
│  │ LLM Safety   │  │ Diffusion    │ │
│  │ Research     │  │ Models       │ │
│  │              │  │              │ │
│  │ 156개 논문   │  │ 89개 논문    │ │
│  │ 1,234명 사용 │  │ 892명 사용   │ │
│  │              │  │              │ │
│  │ by @prof_kim │  │ by @ai_lab   │ │
│  └──────────────┘  └──────────────┘ │
│                                     │
│  [복사하기] → 내 컬렉션으로 복사    │
└─────────────────────────────────────┘
```

---

## 5. 기능 상세 명세

### 5.1 컬렉션 생성

#### 5.1.1 자동 논문 수집

**입력**

- 연구 주제/키워드
- 필터 (연도, 인용 수, Open Access 여부)

**처리 과정**

1. Semantic Scholar API 호출
2. 검색 결과 메타데이터 저장
3. Open Access PDF URL 추출
4. 백그라운드 작업 큐에 추가
   - PDF 다운로드
   - 텍스트 추출
   - 청킹
   - 벡터 임베딩 생성
   - Vector DB 저장

**출력**

- 논문 리스트 (메타데이터)
- Open Access 상태 표시
- 백그라운드 작업 진행 상태

**예외 처리**

- API 호출 실패 → 재시도 (3회)
- PDF 다운로드 실패 → 해당 논문 스킵, 로그 기록
- 파싱 실패 → 에러 표시, 수동 업로드 안내

#### 5.1.2 수동 PDF 업로드

**입력**

- 논문 메타데이터 (자동 입력됨)
- PDF 파일 (사용자 업로드)

**처리 과정**

1. 파일 형식 검증 (PDF만 허용)
2. 파일 크기 검증 (최대 100MB)
3. 임시 스토리지 저장
4. 백그라운드 작업 큐에 추가
   - 텍스트 추출
   - 청킹
   - 벡터 임베딩
   - Vector DB 저장
5. 완료 후 논문 상태 업데이트

**출력**

- "업로드 성공" 메시지
- 진행 상태 표시
- 논문 카드 상태 변경 (⚠️ → ✅)

**제약사항**

- 파일 형식: PDF만
- 최대 파일 크기: 100MB
- 사용자당 수동 업로드 제한: 50개/컬렉션

### 5.2 컬렉션 업데이트

#### 기능 설명

기존 컬렉션의 검색 조건으로 신규 논문 확인 및 추가

**트리거**

- 사용자 수동 클릭: "새 논문 확인" 버튼
- (선택) 자동 업데이트: 주간/월간 스케줄

**처리 과정**

1. 기존 검색 조건 불러오기
2. 마지막 업데이트 날짜 이후 논문 검색
3. 중복 제거 (이미 있는 논문 제외)
4. 신규 논문 리스트 표시
5. 사용자 선택
   - 전체 자동 추가
   - 개별 선택 추가
6. 백그라운드 처리 (자동 수집과 동일)

**출력**

- "N개의 신규 논문 발견" 알림
- 신규 논문 미리보기 리스트
- 추가 완료 후 인사이트 자동 업데이트

**UX 고려사항**

- 신규 논문 있을 시: 홈 화면에서 배지 표시
- 신규 논문 없을 시: "최신 상태입니다 ✅"
- 업데이트 히스토리 기록

### 5.3 AI 대화

#### 5.3.1 대화 시작

**새 대화**

- 빈 대화창 제공
- 제안 질문 표시
- 인사이트 요약 참조 가능

**이전 대화 이어하기**

- 대화 리스트 드롭다운
- 대화 미리보기 (제목, 날짜, 첫 질문)
- 선택 시 전체 기록 로드

#### 5.3.2 질의응답 처리

**입력**

- 사용자 질문 (자유 텍스트)

**처리 과정**

1. 질문 임베딩 생성
2. Vector DB 유사도 검색 (Top-K)
3. 관련 논문 청크 추출
4. LLM에 프롬프트 전달
   - 시스템 프롬프트: "당신은 연구 어시스턴트입니다..."
   - 컨텍스트: 추출된 논문 청크
   - 사용자 질문
5. 답변 생성
6. 인용 정보 파싱
7. 대화 기록 저장

**출력**

- AI 답변 (마크다운 형식)
- 참조 논문 리스트
  - 논문 제목
  - 저자, 연도
  - 클릭 시 해당 논문 상세 이동
- 제안 질문 (다음 단계)

**인용 형식**

```
[1] "Attention mechanism allows the model to..."

📚 참조:
[1] "Attention Is All You Need" (Vaswani et al., 2017)
    → 논문 보기
```

#### 5.3.3 대화 기록 관리

**저장 내용**

- 대화 ID
- 컬렉션 ID
- 생성 날짜
- 메시지 배열
  - 역할 (user/assistant)
  - 내용
  - 타임스탬프
  - 참조 논문 ID

**기능**

- 대화 제목 자동 생성 (첫 질문 기반)
- 대화 제목 수동 수정
- 대화 삭제
- 대화 검색

### 5.4 자동 인사이트 생성

#### 생성 시점

- 컬렉션 최초 생성 완료 시
- 컬렉션 업데이트 완료 시
- 사용자 수동 요청 시

#### 생성 내용

**1. 주요 연구 흐름 (3-5개)**

- 클러스터링 또는 LLM 기반 분석
- 각 흐름별 대표 논문
- 간단한 설명

**2. Top 논문 (5개)**

- 인용 수 기준 상위
- 제목, 저자, 연도, 인용 수
- 한 줄 요약

**3. 최근 트렌드 (최근 1년)**

- 급증한 키워드
- 새로운 연구 방향
- 주요 학회/저널

**4. 놓칠 수 있는 연구 방향**

- LLM 기반 갭 분석
- "이 분야에서 상대적으로 덜 연구된 영역"

#### 표시 방식

- 인사이트 탭 (기본 탭)
- 카드 형태
- 클릭 시 관련 논문으로 이동
- "AI와 대화 시작하기" CTA

### 5.5 컬렉션 공유

#### 공개 설정

- 비공개 (기본)
- 공개
  - 공개 컬렉션 목록에 표시
  - 검색 가능
  - 다른 사용자가 복사 가능

#### 복사 기능

- "복사하기" 버튼
- 논문 메타데이터 + Vector DB 참조 복사
- 사용자별 대화는 독립적

#### 통계

- 사용자 수
- 복사 횟수
- (선택) 좋아요

---

## 6. 데이터 구조

### 6.1 주요 엔티티

#### User (사용자)

```
{
  userId: string
  email: string
  name: string
  createdAt: timestamp
  subscription: string // "free", "pro"
}
```

#### Collection (컬렉션)

```
{
  collectionId: string
  userId: string
  name: string
  description: string
  searchQuery: string // 원본 검색어
  filters: {
    yearFrom: number
    yearTo: number
    minCitations: number
    openAccessOnly: boolean
  }
  isPublic: boolean
  createdAt: timestamp
  lastUpdatedAt: timestamp
  paperCount: number
  insightSummary: object // 자동 생성 인사이트
}
```

#### Paper (논문)

```
{
  paperId: string // Semantic Scholar ID
  title: string
  authors: array
  year: number
  abstract: string
  citationCount: number
  publicationType: string
  venue: string
  openAccessPdf: {
    url: string | null
    status: string // "GOLD", "GREEN", "BRONZE", null
  }
  semanticScholarUrl: string
  addedToCollections: array // 어느 컬렉션에 포함되는지
  vectorStatus: string // "pending", "completed", "failed"
  pdfSource: string // "auto" | "manual"
  uploadedBy: string | null // 수동 업로드 시 userId
}
```

#### Conversation (대화)

```
{
  conversationId: string
  collectionId: string
  userId: string
  title: string // 자동 생성 또는 수정
  messages: [
    {
      role: "user" | "assistant"
      content: string
      timestamp: timestamp
      citedPapers: array // assistant만 해당
    }
  ]
  createdAt: timestamp
  lastMessageAt: timestamp
}
```

### 6.2 Vector DB 구조

```
{
  chunkId: string
  paperId: string
  collectionIds: array // 여러 컬렉션에서 공유
  text: string
  embedding: vector
  metadata: {
    title: string
    authors: array
    year: number
    chunkIndex: number
    totalChunks: number
  }
}
```

---

## 7. UX 가이드라인

### 7.1 진행 상태 표시

#### 백그라운드 작업

- 명확한 진행률 표시
- 예상 완료 시간
- 실시간 업데이트

**예시:**

```
⏳ 논문 다운로드 중... (15/42)
예상 완료 시간: 약 3분
```

#### 에러 처리

- 사용자 친화적 메시지
- 다음 행동 제안
- 에러 상세 (선택적 확장)

**예시:**

```
⚠️ 일부 논문을 다운로드하지 못했습니다 (3/42)

원인: PDF 파일을 찾을 수 없음
해결: 나중에 수동으로 업로드할 수 있습니다

[상세 보기] [계속 진행]
```

### 7.2 빈 상태 (Empty State)

#### 논문 없음

```
📚 아직 논문이 없습니다

"새 논문 확인" 버튼을 눌러
최신 논문을 추가해보세요

[새 논문 확인]
```

#### 대화 없음

```
💬 첫 대화를 시작해보세요

추천 질문:
• 이 분야의 주요 연구 흐름은?
• 가장 많이 인용된 논문은?
• 최근 트렌드는 무엇인가요?
```

### 7.3 온보딩

#### 첫 방문 시

1. 환영 모달
2. 간단한 제품 소개 (3 슬라이드)
3. 샘플 컬렉션 제공 (선택)
4. "첫 컬렉션 만들기" 유도

#### 툴팁

- 주요 기능에 툴팁 표시 (첫 사용 시)
- "다시 보지 않기" 옵션

### 7.4 반응형 디자인

#### 데스크톱 우선

- 최소 화면 너비: 1024px
- 2단 레이아웃 (논문 리스트 + 대화)

#### 모바일 대응 (MVP 후)

- 현재는 "모바일에서는 데스크톱 버전 사용 권장" 안내

---

## 8. 성공 지표

### 8.1 사용자 참여도

- **컬렉션 생성률**: 신규 사용자의 80% 이상이 첫 컬렉션 생성
- **컬렉션당 논문 수**: 평균 30개 이상
- **대화 참여율**: 컬렉션 생성 사용자의 70% 이상이 AI와 대화
- **평균 대화 길이**: 대화당 평균 10회 이상 메시지 교환

### 8.2 재방문 및 리텐션

- **주간 활성 사용자(WAU)**: 가입 후 4주 내 40% 이상
- **컬렉션 업데이트율**: 월 1회 이상 업데이트하는 사용자 50%
- **대화 재개율**: 이전 대화를 이어가는 비율 30% 이상

### 8.3 기능 사용률

- **수동 PDF 업로드**: 사용자의 20% 이상이 1개 이상 업로드
- **공개 컬렉션 활용**: 공개 컬렉션 복사 또는 참조 월 100회 이상
- **인사이트 조회율**: 컬렉션 생성 후 80% 이상이 인사이트 탭 확인

### 8.4 품질 지표

- **답변 만족도**: "도움이 되었나요?" 설문 70% 이상 긍정
- **에러율**: PDF 처리 실패율 10% 이하
- **응답 시간**: AI 답변 생성 평균 5초 이내

---

## 9. 개발 로드맵

### Phase 1: Core Foundation (2-3주)

**목표**: 기본 논문 수집 및 저장 구현

- [ ] 사용자 인증 (회원가입/로그인)
- [ ] Semantic Scholar API 연동
- [ ] Open Access PDF 자동 다운로드
- [ ] 백그라운드 작업 큐 구축
- [ ] Vector DB 설정 및 임베딩 저장
- [ ] 컬렉션 생성 UI

**완료 기준**: 사용자가 주제를 입력하면 논문이 자동으로 수집되고 Vector DB에 저장됨

---

### Phase 2: AI Conversation (2주)

**목표**: RAG 기반 대화 기능 구현

- [ ] RAG 파이프라인 구축
- [ ] LLM 연동 (Gemini File Search)
- [ ] 인용 추출 및 표시
- [ ] 대화 UI 구현
- [ ] 대화 기록 저장
- [ ] 논문 리스트 UI

**완료 기준**: 사용자가 질문하면 논문 기반 답변이 인용과 함께 제공됨

---

### Phase 3: Manual Upload (1주)

**목표**: Non-Open Access 논문 수동 업로드

- [ ] PDF 업로드 UI
- [ ] 파일 검증 로직
- [ ] 수동 업로드 백그라운드 처리
- [ ] 논문 상태 관리 (Open Access vs Manual)
- [ ] 에러 핸들링 및 사용자 피드백

**완료 기준**: 사용자가 PDF를 업로드하면 대화에서 참조 가능

---

### Phase 4: Conversation History (1주)

**목표**: 대화 기록 관리

- [ ] 대화 리스트 UI
- [ ] 대화 선택 및 로드
- [ ] 새 대화 vs 이어하기 구분
- [ ] 대화 제목 자동 생성
- [ ] 대화 제목 수정/삭제

**완료 기준**: 사용자가 이전 대화를 선택하면 전체 기록이 로드되어 이어서 대화 가능

---

### Phase 5: Collection Update (1주)

**목표**: 신규 논문 추가 기능

- [ ] "새 논문 확인" API 로직
- [ ] 중복 제거 로직
- [ ] 신규 논문 미리보기 UI
- [ ] 선택적 추가 기능
- [ ] 업데이트 히스토리 기록
- [ ] 업데이트 후 인사이트 재생성

**완료 기준**: 사용자가 버튼 클릭 시 신규 논문이 발견되고 선택적으로 추가 가능

---

### Phase 6: Insights Dashboard (1-2주)

**목표**: 자동 인사이트 생성

- [ ] 논문 클러스터링 또는 LLM 분석
- [ ] 주요 연구 흐름 추출
- [ ] Top 논문 정리
- [ ] 최근 트렌드 분석
- [ ] 갭 분석 (놓칠 수 있는 연구 방향)
- [ ] 인사이트 UI 구현
- [ ] 제안 질문 생성

**완료 기준**: 컬렉션 생성 완료 시 자동으로 인사이트가 생성되어 표시됨

---

### Phase 7: Public Collections (1주)

**목표**: 컬렉션 공유 기능

- [ ] 공개/비공개 설정
- [ ] 공개 컬렉션 목록 UI
- [ ] 컬렉션 복사 기능
- [ ] 검색 및 필터
- [ ] 통계 표시 (사용자 수, 복사 횟수)

**완료 기준**: 사용자가 컬렉션을 공개로 설정하면 다른 사용자가 찾아서 복사 가능

---

### Phase 8: Polish & Testing (1주)

**목표**: UX 개선 및 버그 수정

- [ ] 진행 상태 표시 개선
- [ ] 에러 메시지 최적화
- [ ] 빈 상태 UI
- [ ] 온보딩 플로우
- [ ] 성능 최적화
- [ ] 통합 테스트
- [ ] 사용자 테스트

**완료 기준**: 전체 플로우가 매끄럽게 동작하며, 사용자 피드백 긍정적

---

### 총 개발 기간: 10-12주

---

## 10. 부록

### 10.1 용어 정의

- **컬렉션**: 특정 주제에 대한 논문 모음
- **Open Access**: 무료로 접근 가능한 논문
- **벡터화**: 텍스트를 숫자 벡터로 변환하는 과정
- **RAG**: Retrieval-Augmented Generation, 검색 기반 답변 생성
- **인사이트**: AI가 자동으로 생성한 연구 동향 요약

### 10.2 참고 자료

- Semantic Scholar API: https://api.semanticscholar.org/
- Elicit (경쟁 제품): https://elicit.com/

---

**문서 버전**: v1.0  
**작성일**: 2024-11-15  
**다음 리뷰**: Phase 3 완료 후
